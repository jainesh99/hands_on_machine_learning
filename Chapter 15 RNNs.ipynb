{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:  [[[-0.23643036]\n",
      "  [-0.18228617]\n",
      "  [-0.0568142 ]\n",
      "  ...\n",
      "  [-0.6167866 ]\n",
      "  [-0.41807923]\n",
      "  [-0.3014103 ]]\n",
      "\n",
      " [[ 0.19118749]\n",
      "  [ 0.2934651 ]\n",
      "  [ 0.3949101 ]\n",
      "  ...\n",
      "  [ 0.31614634]\n",
      "  [ 0.41594025]\n",
      "  [ 0.5356735 ]]\n",
      "\n",
      " [[ 0.52464515]\n",
      "  [ 0.44103223]\n",
      "  [ 0.17760512]\n",
      "  ...\n",
      "  [-0.18592957]\n",
      "  [ 0.16615519]\n",
      "  [ 0.4090717 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.3023711 ]\n",
      "  [-0.08316951]\n",
      "  [ 0.01961296]\n",
      "  ...\n",
      "  [-0.21473475]\n",
      "  [ 0.00953582]\n",
      "  [ 0.22411552]]\n",
      "\n",
      " [[ 0.6569381 ]\n",
      "  [ 0.7006996 ]\n",
      "  [ 0.531717  ]\n",
      "  ...\n",
      "  [-0.35150713]\n",
      "  [-0.2821114 ]\n",
      "  [-0.31063786]]\n",
      "\n",
      " [[ 0.07315657]\n",
      "  [-0.13301802]\n",
      "  [-0.19905634]\n",
      "  ...\n",
      "  [ 0.58108896]\n",
      "  [ 0.4785419 ]\n",
      "  [ 0.27502358]]]\n",
      "(10000, 51, 1)\n",
      "X Train: [[[-0.23643036]\n",
      "  [-0.18228617]\n",
      "  [-0.0568142 ]\n",
      "  ...\n",
      "  [-0.6753009 ]\n",
      "  [-0.6167866 ]\n",
      "  [-0.41807923]]\n",
      "\n",
      " [[ 0.19118749]\n",
      "  [ 0.2934651 ]\n",
      "  [ 0.3949101 ]\n",
      "  ...\n",
      "  [ 0.10951188]\n",
      "  [ 0.31614634]\n",
      "  [ 0.41594025]]\n",
      "\n",
      " [[ 0.52464515]\n",
      "  [ 0.44103223]\n",
      "  [ 0.17760512]\n",
      "  ...\n",
      "  [-0.36192834]\n",
      "  [-0.18592957]\n",
      "  [ 0.16615519]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.5841694 ]\n",
      "  [-0.34716234]\n",
      "  [-0.07689546]\n",
      "  ...\n",
      "  [ 0.17996863]\n",
      "  [ 0.31874326]\n",
      "  [ 0.4795096 ]]\n",
      "\n",
      " [[ 0.47529757]\n",
      "  [ 0.5533553 ]\n",
      "  [ 0.530499  ]\n",
      "  ...\n",
      "  [ 0.3298888 ]\n",
      "  [ 0.33440745]\n",
      "  [ 0.26028082]]\n",
      "\n",
      " [[-0.03493262]\n",
      "  [ 0.19130243]\n",
      "  [ 0.41433752]\n",
      "  ...\n",
      "  [-0.18005984]\n",
      "  [-0.16953127]\n",
      "  [-0.28270212]]]\n",
      "(7000, 50, 1)\n",
      "Y Train:  [[-0.3014103 ]\n",
      " [ 0.5356735 ]\n",
      " [ 0.4090717 ]\n",
      " ...\n",
      " [ 0.5560029 ]\n",
      " [ 0.12755625]\n",
      " [-0.3087101 ]]\n",
      "(7000, 1)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n",
    "\n",
    "print('Series: ',series)\n",
    "print(series.shape)\n",
    "print('X Train:',X_train)\n",
    "print(X_train.shape)\n",
    "print('Y Train: ',y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(series[0, :], '-g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a naive forecasting which takes the last column and sets it to predicted and then compares it to the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021135446"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a linear model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50,1]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 1s 79us/sample - loss: 0.1723 - val_loss: 0.0520\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0387 - val_loss: 0.0271\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.0226 - val_loss: 0.0175\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0154 - val_loss: 0.0131\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.0043 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 3s 438us/sample - loss: 0.2816 - val_loss: 0.2438\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 311us/sample - loss: 0.2387 - val_loss: 0.2062\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 323us/sample - loss: 0.2010 - val_loss: 0.1749\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 310us/sample - loss: 0.1690 - val_loss: 0.1491\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 322us/sample - loss: 0.1438 - val_loss: 0.1292\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 307us/sample - loss: 0.1223 - val_loss: 0.1090\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 307us/sample - loss: 0.1006 - val_loss: 0.0883\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 311us/sample - loss: 0.0812 - val_loss: 0.0709\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 324us/sample - loss: 0.0647 - val_loss: 0.0558\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 307us/sample - loss: 0.0504 - val_loss: 0.0431\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 328us/sample - loss: 0.0385 - val_loss: 0.0327\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 305us/sample - loss: 0.0291 - val_loss: 0.0248\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 305us/sample - loss: 0.0222 - val_loss: 0.0193\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 307us/sample - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 323us/sample - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 312us/sample - loss: 0.0131 - val_loss: 0.0128\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 307us/sample - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 315us/sample - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 308us/sample - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 327us/sample - loss: 0.0118 - val_loss: 0.0120\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True,input_shape=[None,1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0408 - val_loss: 0.0094\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 7s 992us/sample - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 7s 991us/sample - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 7s 987us/sample - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 7s 989us/sample - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 7s 992us/sample - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 7s 987us/sample - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 7s 1ms/sample - loss: 0.0031 - val_loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True,input_shape=[None,1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 6s 919us/sample - loss: 0.0229 - val_loss: 0.0055\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 6s 881us/sample - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 6s 793us/sample - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 5s 723us/sample - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 6s 824us/sample - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 6s 841us/sample - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 7s 965us/sample - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 5s 785us/sample - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 5s 724us/sample - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 5s 715us/sample - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 5s 716us/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 6s 814us/sample - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 5s 741us/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 5s 736us/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 6s 803us/sample - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 6s 794us/sample - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 6s 880us/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 6s 882us/sample - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 5s 774us/sample - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 5s 705us/sample - loss: 0.0028 - val_loss: 0.0028\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting several timesteps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.5681477 ]\n",
      "  [ 0.6573052 ]\n",
      "  [ 0.6553215 ]\n",
      "  [ 0.5776591 ]\n",
      "  [ 0.452183  ]\n",
      "  [ 0.31786132]\n",
      "  [ 0.19753003]\n",
      "  [ 0.10179821]\n",
      "  [ 0.03371797]\n",
      "  [-0.01196287]]]\n"
     ]
    }
   ],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a sequence to model pattern, and in this case, you would need to just change the Dense(1) to Dense(10), but make sure your input data changes accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the TimeDistributed which does the reshaping for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to deal woth unstable gradients with RNNs is to use LayerNormalisation, unfortunately this has to be done manually, as there is no layer normalisation code yet in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM which can be used to remember the beginning so to speak\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can also be done to help is that you can add a 1D Conv net in order to assist the RNN and in particular a GRU cell which is similar to LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-de97d525a1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None,1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, Y_train[:, 3::2], epochs=20, validation_data=(X_valid, Y_valid[:,3::2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
