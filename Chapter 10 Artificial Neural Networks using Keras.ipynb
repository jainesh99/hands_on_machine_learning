{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('ch10ann.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a single Threshold Linear Unit (TLU) which is known as a perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data[:, (2,3)] #petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "print('Predicted', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.1.0\n",
      "Keras version:  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print('Tensorflow version: ',tf.__version__)\n",
    "print('Keras version: ',keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification using Fashion Mnist, this is different from Mnist as Mnist was digits [0,1,2,3,4,5...9] whereas Fashion Mnist is clothing: Tshirt, trouser, pullover etc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 38s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape\n",
    "#You have 60000 28 by 28 elements in teh array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the pixel intensities, since all are from 0 to 255 -> 0 to 1, also creating a validation set\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \n",
    "               \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets build our MLP\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) #Convert input to a 1D array\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) #300 Neurons with Relu activation function\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "#All of this can also be parsed as paramters inside Sequential\n",
    "#model = keras.models.Sequential([\n",
    "#    keras.layers.Flatten(input_shape=[28,28]),\n",
    "#    keras.layers.Dense(300, activation=\"relu\"),\n",
    "#    keras.layers.Dense(100, activation=\"relu\"),\n",
    "#    keras.layers.Dense(10, activation=\"softmax\")\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x15272f860>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15270b4a8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15270b748>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15261d630>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00064065, -0.05406202,  0.06755719, ...,  0.04977856,\n",
       "         0.0735604 ,  0.00520879],\n",
       "       [ 0.03916007,  0.05973338, -0.02302288, ...,  0.06761892,\n",
       "         0.06866913,  0.00079568],\n",
       "       [ 0.06503299, -0.05525991,  0.05248441, ..., -0.01200636,\n",
       "        -0.01764258, -0.03057273],\n",
       "       ...,\n",
       "       [-0.0018555 , -0.02894144, -0.06312636, ..., -0.07225871,\n",
       "         0.05890697,  0.00673521],\n",
       "       [ 0.03758623,  0.02471546, -0.02648306, ..., -0.07403474,\n",
       "        -0.07191742,  0.0514216 ],\n",
       "       [-0.00858812,  0.02415555,  0.02097904, ..., -0.03425112,\n",
       "        -0.05430547, -0.02035681]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "#Can also use other ones which is the same and do not have to write the actual word for instance\n",
    "# sgd = keras.optimizers.SGD(), default learning rate = 0.01\n",
    "# Using sparse becuase we have 1 to 9 and it has not been one hot encoded\n",
    "# Can be converted have to use keras.utils.to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2219 - accuracy: 0.9199 - val_loss: 0.3085 - val_accuracy: 0.8912\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2189 - accuracy: 0.9208 - val_loss: 0.2943 - val_accuracy: 0.8944\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2148 - accuracy: 0.9220 - val_loss: 0.2951 - val_accuracy: 0.8918\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.2115 - accuracy: 0.9241 - val_loss: 0.2970 - val_accuracy: 0.8898\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2076 - accuracy: 0.9255 - val_loss: 0.3069 - val_accuracy: 0.8918\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.2053 - accuracy: 0.9269 - val_loss: 0.2860 - val_accuracy: 0.8980\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.2011 - accuracy: 0.9278 - val_loss: 0.2992 - val_accuracy: 0.8952\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1989 - accuracy: 0.9287 - val_loss: 0.2922 - val_accuracy: 0.8960\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.1943 - accuracy: 0.9298 - val_loss: 0.2872 - val_accuracy: 0.8970\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1922 - accuracy: 0.9315 - val_loss: 0.3326 - val_accuracy: 0.8882\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1903 - accuracy: 0.9319 - val_loss: 0.2971 - val_accuracy: 0.8922\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1854 - accuracy: 0.9342 - val_loss: 0.3007 - val_accuracy: 0.8948\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1832 - accuracy: 0.9348 - val_loss: 0.2948 - val_accuracy: 0.8938\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1795 - accuracy: 0.9358 - val_loss: 0.2852 - val_accuracy: 0.8994\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1787 - accuracy: 0.9361 - val_loss: 0.2878 - val_accuracy: 0.8970\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.1746 - accuracy: 0.9370 - val_loss: 0.2902 - val_accuracy: 0.8988\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1721 - accuracy: 0.9379 - val_loss: 0.2992 - val_accuracy: 0.8944\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.1688 - accuracy: 0.9396 - val_loss: 0.2871 - val_accuracy: 0.8992\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1654 - accuracy: 0.9414 - val_loss: 0.2916 - val_accuracy: 0.8952\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.1629 - accuracy: 0.9424 - val_loss: 0.3266 - val_accuracy: 0.8880\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.1619 - accuracy: 0.9424 - val_loss: 0.3405 - val_accuracy: 0.8798\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.1581 - accuracy: 0.9440 - val_loss: 0.3305 - val_accuracy: 0.8866\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.1557 - accuracy: 0.9451 - val_loss: 0.2948 - val_accuracy: 0.8980\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.1537 - accuracy: 0.9459 - val_loss: 0.3378 - val_accuracy: 0.8868\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.1508 - accuracy: 0.9463 - val_loss: 0.2971 - val_accuracy: 0.8970\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.1495 - accuracy: 0.9477 - val_loss: 0.3556 - val_accuracy: 0.8828\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.1458 - accuracy: 0.9486 - val_loss: 0.3460 - val_accuracy: 0.8808\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.1425 - accuracy: 0.9496 - val_loss: 0.3106 - val_accuracy: 0.8968\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.1416 - accuracy: 0.9509 - val_loss: 0.3034 - val_accuracy: 0.8968\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.1404 - accuracy: 0.9502 - val_loss: 0.2995 - val_accuracy: 0.8990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n",
    "# Can also use validation split = 0.1 which tells keras to use the last 10% of the data (before shuffling) for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('ch10ann.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
